{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:12.391883Z",
     "start_time": "2019-11-10T12:05:12.386093Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:15.234619Z",
     "start_time": "2019-11-10T12:05:13.581501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit([\n",
    " 'bind_debit_card',\n",
    " 'biometric_auto',\n",
    " 'contacts_info',\n",
    " 'id_verify',\n",
    " 'loan_index',\n",
    " 'loan_submission',\n",
    " 'login',\n",
    " 'operator',\n",
    " 'personal_info',\n",
    " 'register',\n",
    " 'unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:17.273673Z",
     "start_time": "2019-11-10T12:05:15.237316Z"
    }
   },
   "outputs": [],
   "source": [
    "# data generator body\n",
    "\n",
    "def file_generator(filename):\n",
    "    '''\n",
    "    create a generator for files\n",
    "    '''\n",
    "    i = -1\n",
    "    while True:\n",
    "        i+=1\n",
    "        if i<len(filename):\n",
    "            yield filename[i]\n",
    "        else:\n",
    "            i=-1\n",
    "            \n",
    "def data_generator(file_list, batch_size = 32, total_batch = 1000):\n",
    "    if type(file_list)!=list:\n",
    "        file_gen = file_generator([file_list])\n",
    "    else:\n",
    "        file_gen = file_generator(file_list)\n",
    "    file_name = next(file_gen)\n",
    "    f = open(file_name, 'r')\n",
    "    while True:\n",
    "        n_batch = 0\n",
    "        pointer = 1\n",
    "        while n_batch<total_batch:\n",
    "            pointer = 0\n",
    "            b_sequence = []\n",
    "            p_staytime_sequence = []\n",
    "            p_lag_sequence = []\n",
    "            info_sequence = []\n",
    "            while pointer<batch_size:\n",
    "                pointer += 1\n",
    "                line = next(f)\n",
    "                data_body = json.loads(line)\n",
    "                user_id = data_body[0]\n",
    "                apply_time, label = data_body[1]['order_info']['order_time'],data_body[1]['order_info']['label']\n",
    "                page_sequence, page_stay_time, page_lagg_time = data_process(data_body[1]['data'])\n",
    "                b_sequence.append(page_sequence)\n",
    "                p_staytime_sequence.append(page_stay_time)\n",
    "                p_lag_sequence.append(page_lagg_time)\n",
    "                info_sequence.append([user_id, label, apply_time])\n",
    "            n_batch +=1\n",
    "            b_sequence = pad_sequences(b_sequence, maxlen=20, dtype='int64', padding='pre')\n",
    "            p_staytime_sequence = pad_sequences(p_staytime_sequence, maxlen=20, dtype='int64', padding='pre')\n",
    "            p_lag_sequence = pad_sequences(p_lag_sequence, maxlen=20, dtype='int64', padding='pre')\n",
    "            yield b_sequence, [x[1] for x in info_sequence]\n",
    "                 # p_staytime_sequence,\\\n",
    "                 # p_lag_sequence,info_sequence\n",
    "            b_sequence = []\n",
    "            p_staytime_sequence = []\n",
    "            p_lag_sequence = []\n",
    "            info_sequence = []\n",
    "    file_name = next(file_gen)\n",
    "    f = open(file_name, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:17.588791Z",
     "start_time": "2019-11-10T12:05:17.278899Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_process(sequence_for_a_single_application):\n",
    "    sequence_for_a_single_application.sort(key=lambda x : x['petime'])\n",
    "    \n",
    "    page_sequence = [x['pname'] for x in sequence_for_a_single_application]\n",
    "    \n",
    "    pstart = [x['pstime'] for x in sequence_for_a_single_application]\n",
    "    \n",
    "    pend = ([x['petime'] for x in sequence_for_a_single_application])\n",
    "    \n",
    "    page_stay_time = [(y-x)/1000 for x,y in zip(pstart, pend)]\n",
    "    \n",
    "    page_lagg_time = [(x-y)/1000 if (x-y)//1000<600 else -1 for x,y in zip(pstart[1:], pend[:-1])] \n",
    "    # calculate the duration between the end of last action and the start of current action\n",
    "    # if this lag is more than 10 minutes we ignore the quantitative meaning of this value\n",
    "    \n",
    "    page_sequence = le.transform(page_sequence)\n",
    "    return page_sequence, page_stay_time, page_lagg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:17.758344Z",
     "start_time": "2019-11-10T12:05:17.593057Z"
    }
   },
   "outputs": [],
   "source": [
    "a = data_generator(['../data/raw/dataForSequentialEmbedding/data_train.json'], batch_size = 16) # iteratively read and process data from raw sequential_behavior\n",
    "# batch_size controls how much data it process each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:17.986761Z",
     "start_time": "2019-11-10T12:05:17.762221Z"
    }
   },
   "outputs": [],
   "source": [
    "test = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:20.295317Z",
     "start_time": "2019-11-10T12:05:17.990641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4, 4, 4, 5, 5, 6, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 6, 4, 4, 5],\n",
       "        [4, 5, 4, 4, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 5, 4, 5, 5, 4],\n",
       "        [4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 7, 7, 4, 4, 4, 5],\n",
       "        [1, 1, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 7, 7, 4, 0, 0, 4, 5],\n",
       "        [8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 7, 7, 4, 4, 0, 0, 4, 5, 4, 4],\n",
       "        [6, 4, 4, 4, 5, 4, 4, 5, 4, 4, 4, 5, 5, 4, 5, 4, 5, 4, 5, 4],\n",
       "        [2, 2, 2, 7, 4, 4, 4, 4, 0, 0, 4, 5, 4, 4, 5, 4, 4, 5, 5, 4],\n",
       "        [4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 7, 4, 4, 5, 4, 4, 4, 5, 5, 4],\n",
       "        [8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 7, 4, 4, 0, 0, 0, 4, 5],\n",
       "        [4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5],\n",
       "        [1, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 7, 4, 4, 0, 0, 4, 5, 4],\n",
       "        [5, 5, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 4],\n",
       "        [4, 5, 5, 4, 4, 4, 7, 4, 4, 5, 4, 4, 4, 5, 5, 4, 4, 4, 5, 4],\n",
       "        [0, 0, 3, 3, 8, 8, 2, 2, 7, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4],\n",
       "        [4, 4, 4, 4, 0, 0, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5],\n",
       "        [0, 0, 0, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 6, 4, 4, 4, 5]]),\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mtf trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:23.536279Z",
     "start_time": "2019-11-10T12:05:20.300942Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout,Reshape,Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import Conv1D,Conv2D, Reshape\n",
    "from keras.layers import MaxPooling1D, Embedding,LSTM, MaxPooling2D, Bidirectional, SimpleRNN, UpSampling1D\n",
    "from keras.models import Model,Sequential\n",
    "import sys\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:23.826336Z",
     "start_time": "2019-11-10T12:05:23.540652Z"
    }
   },
   "outputs": [],
   "source": [
    "mtf = pd.read_parquet('mtf.parquet') # let's suppose this is the mtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:23.908294Z",
     "start_time": "2019-11-10T12:05:23.828665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bind_debit_card\n",
      "1 biometric_auto\n",
      "2 contacts_info\n",
      "3 id_verify\n",
      "4 loan_index\n",
      "5 loan_submission\n",
      "6 login\n",
      "7 operator\n",
      "8 personal_info\n",
      "9 register\n"
     ]
    }
   ],
   "source": [
    "# constructing embedding matrix\n",
    "mtf_matrix = np.zeros(shape=(11,11))\n",
    "\n",
    "for n,item in enumerate(le.classes_):\n",
    "    if item == 'unknown':\n",
    "        pass\n",
    "    else:\n",
    "        mtf_matrix[n,:] = mtf.loc[f'to_{item}'].values\n",
    "        print(n, item)\n",
    "        \n",
    "mtf_matrix = StandardScaler().fit_transform(mtf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:24.094197Z",
     "start_time": "2019-11-10T12:05:23.911424Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 20:05:24.062738 140605509134144 deprecation_wrapper.py:119] From /home/craiditx/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(input_dim = 11,\n",
    "                            output_dim = 11,\n",
    "                            weights=[mtf_matrix],\n",
    "                            input_length=20,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T12:05:25.909048Z",
     "start_time": "2019-11-10T12:05:24.096239Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 20:05:24.246940 140605509134144 deprecation_wrapper.py:119] From /home/craiditx/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1110 20:05:24.256791 140605509134144 deprecation_wrapper.py:119] From /home/craiditx/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1110 20:05:24.270979 140605509134144 deprecation_wrapper.py:119] From /home/craiditx/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1110 20:05:24.272225 140605509134144 deprecation_wrapper.py:119] From /home/craiditx/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 20, 11)            121       \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 20, 11, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 11, 16)        80        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 11, 8)         520       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 11, 4)         132       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 11, 1)         17        \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 11, 20)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 11, 20)            3280      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 11, 16)            2368      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8)                 800       \n",
      "=================================================================\n",
      "Total params: 7,318\n",
      "Trainable params: 7,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape = (20,)) # sequence with 20 sequential behavior\n",
    "input_layer = Model(input_layer,input_layer)\n",
    "\n",
    "embedding_model = Sequential()\n",
    "embedding_model.add(input_layer)\n",
    "embedding_model.add(embedding_layer) # embedded behavior. (None, n_timestamp, n_dim_embedding)\n",
    "\n",
    "embedding_model.add(Reshape((20,11,1)))\n",
    "embedding_model.add(Conv2D(16, (2,2), padding='same'))\n",
    "embedding_model.add(Conv2D(8, (2,2), padding='same'))\n",
    "embedding_model.add(Conv2D(4, (2,2), padding='same'))\n",
    "embedding_model.add(Conv2D(1, (2,2), padding='same'))\n",
    "\n",
    "embedding_model.add(Reshape((11,20)))\n",
    "\n",
    "embedding_model.add(LSTM(20,return_sequences=True))\n",
    "embedding_model.add(LSTM(16,return_sequences=True))\n",
    "embedding_model.add(LSTM(8,return_sequences=False))\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after feature extracting layer you can add any kinds of other layers.\n",
    "# normally after this we combine page stay time and lag sequence as weights to do attention\n",
    "## or merged layer.\n",
    "\n",
    "# tricks 1 : you can mask all the '-1' value in lag sequence\n",
    "# tricks 2 : try api modeling not sequential modeling using keras, cause sometimes state carried by LSTM can be useful"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
